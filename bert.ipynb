{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from textwrap import wrap\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aint ever trapped bando oh lord dont get wrong...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink go smoke go feel got let go care get los...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dont live planet earth found love venus thats ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trippin grigio mobbin light low trippin grigio...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see midnight panther gallant brave found found...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics sentiment\n",
       "0  aint ever trapped bando oh lord dont get wrong...  positive\n",
       "1  drink go smoke go feel got let go care get los...  positive\n",
       "2  dont live planet earth found love venus thats ...  negative\n",
       "3  trippin grigio mobbin light low trippin grigio...   neutral\n",
       "4  see midnight panther gallant brave found found...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/original_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158353, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158353 entries, 0 to 158352\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   lyrics     158072 non-null  object\n",
      " 1   sentiment  158353 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df['sentiment'] = df['sentiment'].replace(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aint ever trapped bando oh lord dont get wrong...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink go smoke go feel got let go care get los...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dont live planet earth found love venus thats ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trippin grigio mobbin light low trippin grigio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see midnight panther gallant brave found found...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158348</th>\n",
       "      <td>live borrowed time headshot pretty good ive sc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158349</th>\n",
       "      <td>frozin time forever carrying torch long hear h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158350</th>\n",
       "      <td>hard girl nice boy room night pretty site here...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158351</th>\n",
       "      <td>want chose die buried rubix cube sleep inside ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158352</th>\n",
       "      <td>musical ladder leaning mountain bathed white l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lyrics  sentiment\n",
       "0       aint ever trapped bando oh lord dont get wrong...          2\n",
       "1       drink go smoke go feel got let go care get los...          2\n",
       "2       dont live planet earth found love venus thats ...          0\n",
       "3       trippin grigio mobbin light low trippin grigio...          1\n",
       "4       see midnight panther gallant brave found found...          0\n",
       "...                                                   ...        ...\n",
       "158348  live borrowed time headshot pretty good ive sc...          2\n",
       "158349  frozin time forever carrying torch long hear h...          1\n",
       "158350  hard girl nice boy room night pretty site here...          2\n",
       "158351  want chose die buried rubix cube sleep inside ...          0\n",
       "158352  musical ladder leaning mountain bathed white l...          0\n",
       "\n",
       "[158353 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de código adaptado para o seu dataset\n",
    "sample_idx = 0  # Índice de exemplo a ser utilizado\n",
    "\n",
    "sample_lyrics = df['lyrics'].iloc[sample_idx]  # Texto da letra de música\n",
    "sample_sentiment = df['sentiment'].iloc[sample_idx]  # Sentimento correspondente\n",
    "\n",
    "# Codificar o texto e o sentimento usando o tokenizer\n",
    "encoding = tokenizer.encode_plus(\n",
    "    sample_lyrics,\n",
    "    max_length=32,\n",
    "    add_special_tokens=True,  # Adicionar '[CLS]' e '[SEP]'\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'  # Retornar tensores PyTorch\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  101,  9562,  1204,  1518,  7333,  1467,  1186,  9294,  7692,  1274,\n",
       "         1204,  1243,  2488,  1221,  2337, 11437,  9705,  1161, 13280,  1282,\n",
       "        10565,  1221,  1271,  1474, 13224,  2824,  7533,  1267,  1948,  1299,\n",
       "         1838,   102])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "\n",
    "encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['attention_mask'][0]))\n",
    "\n",
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'ain',\n",
       " '##t',\n",
       " 'ever',\n",
       " 'trapped',\n",
       " 'band',\n",
       " '##o',\n",
       " 'oh',\n",
       " 'lord',\n",
       " 'don',\n",
       " '##t',\n",
       " 'get',\n",
       " 'wrong',\n",
       " 'know',\n",
       " 'couple',\n",
       " 'ni',\n",
       " '##gg',\n",
       " '##a',\n",
       " 'im',\n",
       " 'place',\n",
       " 'everybody',\n",
       " 'know',\n",
       " 'name',\n",
       " 'say',\n",
       " 'gotta',\n",
       " 'watch',\n",
       " 'attitude',\n",
       " 'see',\n",
       " 'money',\n",
       " 'man',\n",
       " 'start',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "df = df.dropna(subset=['lyrics'])  # Remover linhas com valores nulos na coluna 'lyrics'\n",
    "\n",
    "for txt in df['lyrics']:\n",
    "    tokens = tokenizer.encode(txt, max_length=512)\n",
    "    token_lens.append(len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-fee7fabda88f>:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(token_lens)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Token count')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(token_lens)\n",
    "\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "plt.xlabel('Token count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "\n",
    "    self.reviews = reviews\n",
    "\n",
    "    self.targets = targets\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.reviews)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "\n",
    "    review = str(self.reviews[item])\n",
    "\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "\n",
    "      review,\n",
    "\n",
    "      add_special_tokens=True,\n",
    "\n",
    "      max_length=self.max_len,\n",
    "\n",
    "      return_token_type_ids=False,\n",
    "\n",
    "      pad_to_max_length=True,\n",
    "\n",
    "      return_attention_mask=True,\n",
    "\n",
    "      return_tensors='pt',\n",
    "\n",
    "    )\n",
    "\n",
    "    return {\n",
    "\n",
    "      'review_text': review,\n",
    "\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sampled = df_train.sample(n=40000, random_state=42)\n",
    "df_train = df_train_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 2), (7904, 2), (7904, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.lyrics.to_numpy(),\n",
    "\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    max_len=max_len)\n",
    "\n",
    "  return DataLoader(ds, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 200])\n",
      "torch.Size([16, 200])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "\n",
    "print(data['attention_mask'].shape)\n",
    "\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BERT and HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'],\n",
    "  attention_mask=encoding['attention_mask'],\n",
    "  return_dict = False   # this is needed to get a tensor as result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
    "\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "\n",
    "    _, pooled_output = self.bert(\n",
    "\n",
    "      input_ids=input_ids,\n",
    "\n",
    "      attention_mask=attention_mask\n",
    "\n",
    "    )\n",
    "\n",
    "    output = self.drop(pooled_output)\n",
    "\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 200])\n",
      "torch.Size([16, 200])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "\n",
    "print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1955, 0.1314, 0.6731],\n",
       "        [0.4776, 0.3091, 0.2134],\n",
       "        [0.2305, 0.3654, 0.4041],\n",
       "        [0.2995, 0.2282, 0.4723],\n",
       "        [0.2955, 0.2925, 0.4120],\n",
       "        [0.2784, 0.2988, 0.4228],\n",
       "        [0.3290, 0.2747, 0.3964],\n",
       "        [0.3950, 0.2454, 0.3595],\n",
       "        [0.1996, 0.3719, 0.4285],\n",
       "        [0.2191, 0.3974, 0.3836],\n",
       "        [0.3433, 0.3336, 0.3231],\n",
       "        [0.1780, 0.3258, 0.4963],\n",
       "        [0.3094, 0.3743, 0.3163],\n",
       "        [0.2863, 0.3936, 0.3201],\n",
       "        [0.3760, 0.3931, 0.2310],\n",
       "        [0.2971, 0.4607, 0.2422]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(input_ids, attention_mask), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        inputs_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.1191165843725204 accuracy 0.355475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 1.1048741063125702 accuracy 0.35108805668016196\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/pereira/anaconda3/envs/daa/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train))\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, len(df_val))\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
