{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('original_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>no no  i aint ever trapped out the bando  but ...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.626</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>the drinks go down and smoke goes up i feel my...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.630</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>she dont live on planet earth no more  she fou...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.240</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>trippin off that grigio mobbin lights low  tri...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.536</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>i see a midnight panther so gallant and so bra...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.371</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                                                seq  \\\n",
       "0  Elijah Blake  no no  i aint ever trapped out the bando  but ...   \n",
       "1  Elijah Blake  the drinks go down and smoke goes up i feel my...   \n",
       "2  Elijah Blake  she dont live on planet earth no more  she fou...   \n",
       "3  Elijah Blake  trippin off that grigio mobbin lights low  tri...   \n",
       "4  Elijah Blake  i see a midnight panther so gallant and so bra...   \n",
       "\n",
       "                 song  label sentiment  \n",
       "0            Everyday  0.626  positive  \n",
       "1    Live Till We Die  0.630  positive  \n",
       "2       The Otherside  0.240  negative  \n",
       "3               Pinot  0.536   neutral  \n",
       "4  Shadows & Diamonds  0.371  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "comp_score = []\n",
    "sentiment = []\n",
    "\n",
    "for i in df.loc[:,'seq']:\n",
    "    sentiment.append(sia.polarity_scores(i))\n",
    "\n",
    "\n",
    "df.loc[:,'sent_scores'] = sentiment\n",
    "df.loc[:,'comp_score'] = df.loc[:,'sent_scores'].apply(lambda x: x['compound'])\n",
    "df.loc[:,'sentiment_vader'] = df.loc[:,'comp_score'].apply(lambda x: 'Positive' if x>=0.6 else 'Negative' if x<=-0.4 else 'Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pereira/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m sentiment \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mseq\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     sentiment\u001b[39m.\u001b[39mappend(sia\u001b[39m.\u001b[39;49mpolarity_scores(i))\n\u001b[1;32m     10\u001b[0m df\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39msent_scores\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sentiment\n\u001b[1;32m     11\u001b[0m df\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mcomp_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39msent_scores\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/daa/lib/python3.9/site-packages/nltk/sentiment/vader.py:361\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[39mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39mvalence.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m sentitext \u001b[39m=\u001b[39m SentiText(\n\u001b[1;32m    362\u001b[0m     text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mPUNC_LIST, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mREGEX_REMOVE_PUNCTUATION\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m sentiments \u001b[39m=\u001b[39m []\n\u001b[1;32m    365\u001b[0m words_and_emoticons \u001b[39m=\u001b[39m sentitext\u001b[39m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[0;32m~/anaconda3/envs/daa/lib/python3.9/site-packages/nltk/sentiment/vader.py:270\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[0;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, text, punc_list, regex_remove_punctuation):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 270\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(text\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m text\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST \u001b[39m=\u001b[39m punc_list\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "comp_score = []\n",
    "sentiment = []\n",
    "\n",
    "for i in df.loc[:,'seq']:\n",
    "    sentiment.append(sia.polarity_scores(i))\n",
    "\n",
    "df.loc[:,'sent_scores'] = sentiment\n",
    "df.loc[:,'comp_score'] = df.loc[:,'sent_scores'].apply(lambda x: x['compound'])\n",
    "df.loc[:,'sentiment_vader'] = df.loc[:,'comp_score'].apply(lambda x: 'Positive' if x>=0.6 else 'Negative' if x<=-0.4 else 'Neutral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
